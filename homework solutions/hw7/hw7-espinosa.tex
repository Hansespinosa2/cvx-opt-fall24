\section{Homework 7}

\subsection{Exercise 8.16}
This problem involves formulating the following problewm as a convex optimization problem: Find the rectangle
\begin{equation}
    R = \{ x \in \mathbb{R}^n | l \preceq x \preceq u  \}
\end{equation}
of maximum volume, enclosed in a polyhedron $P = \{ x | Ax \preceq b \}$ with variables $l, u$.
\\ \\
For this problem, the volume of the rectangle can be defined as 
\begin{equation}
    V(R) = \prod_{i=1}^{n} (u-l)_i
\end{equation}
This is not convex but maximizing this will be equivalent to maximizing
\begin{equation}
    \log V(R) = \sum_{i=1}^n \log (u - l)_i
\end{equation}

We can define the constraint that the rectangle must be in the polyhedron as
\begin{equation}
    \sup_{ l \preceq x \preceq u} Ax  \preceq b 
\end{equation}

Let $A_i$ be the  $i$-th row of A. where $A \in \mathbb{R}^{m \times n}$. We can define $A_i^+$ be the vector where each entry $j$ is $\max\{A_{ij}, 0\}$. Similarly, we define a vector $A_{i}^-$ where each entry $j$ is $\max\{ -A_{ij},0 \}$. We then transform the above constraint into the equivalent

\begin{equation}
    {A_i^+}^\top u - {A_i^-}^\top l \leq b_i \forall i \in \{ 1,\dots, m \}
\end{equation}

The final optimization problem is therefore turned into

\begin{align}
  \text{minimize} & \quad - \sum_{i=1}^n \log(u - l)_i \\
  \text{subject to} & \quad {A_i^+}^\top u - {A_i^-}^\top l \leq b_i \quad \forall i \in \{ 1,\dots, m \} \\
  & \quad l \preceq u
\end{align}

\subsection{Exercise 9.30}
This question is solved in the code notebook with some scrap work present here
\begin{equation}
    \nabla f(x) = A^\top \frac{1}{1-Ax} + 2x \odot \frac{1}{1 - \text{diag(x)}x}
\end{equation}

\begin{equation}
    \nabla^2 f(x) = A^2(\frac{1}{(1-Ax)^2}) + \text{diag(v)}
\end{equation}

where $v$ is a vector with $i$-th entries $\frac{1+x_i^2}{(1-x_i^2)^2}$

\subsection{Additional Exercise HW7.1}
This is solved in the code notebook with some scrap work present here.
\begin{equation}
    x^{(1)}, \dots, x^{(N)}, \quad y^{(1)}, \dots, y^{(M)}, \quad z^{(1)}, \dots, z^{(P)}
\end{equation}

\begin{equation}
    f_i(z) = a_i^\top z - b_i, \quad i=1,2,3
\end{equation}

\begin{gather}
    f_1(x^{(j)}) > \max \{ f_2(x^{(j)}), f_3(x^{(j)}) \}, \quad j=1,\dots,N \\
    f_2(y^{(j)}) > \max \{ f_1(y^{(j)}), f_3(y^{(j)}) \}, \quad j=1,\dots,M \\
    f_3(z^{(j)}) > \max \{ f_1(z^{(j)}), f_2(z^{(j)}) \}, \quad j=1,\dots,P \\
\end{gather}

\begin{gather}
    R_1 = \{ z | f_1(z) > \max \{ f_2(z), f_3(z) \} \} \\
    R_2 = \{ z | f_2(z) > \max \{ f_1(z), f_3(z) \} \} \\
    R_3 = \{ z | f_3(z) > \max \{ f_1(z), f_2(z) \} \}
\end{gather}

I think one way to approach this problem is to think about it as three separate linear classifiers that must intersect. This approach will use a robust linear classifier with three regions

\begin{align}
  \text{minimize} & \quad -u - w - v \\
  \text{subject to} & \quad f_1(x^{(j)}) \geq \max \{ f_2(x^{(j)}), f_3(x^{(j)}) \} + u \\
  & \quad f_2(y^{(j)}) \geq \max \{ f_1(y^{(j)}), f_3(y^{(j)}) \} + w \\
  & \quad f_3(z^{(j)}) \geq \max \{ f_1(z^{(j)}), f_2(z^{(j)}) \} + v \\
  & \quad \sum_i a_i = 0 \\
  & \quad \sum_i b_i = 0
\end{align}